<div align="center">

<img src="https://readme-typing-svg.herokuapp.com?font=JetBrains+Mono&weight=500&size=24&pause=1000&color=6B7280&center=true&vCenter=true&random=false&width=435&lines=tanmay+sinnarkar" alt="name" />

**data scientist Â· nyc**

*ranking systems Â· exploration problems Â· ml in production*

<br/>

[<img src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" height="25"/>](https://www.linkedin.com/in/tanmay-sinnarkar/)
&nbsp;
[<img src="https://img.shields.io/badge/email-%23EA4335.svg?&style=for-the-badge&logo=gmail&logoColor=white" height="25"/>](mailto:tanu.sinnarkar@gmail.com)

</div>

<br/>

## Â· what i work on Â·

<table>
<tr>
<td width="55%">

```
    user finishes checkout
             â”‚
             â–¼
    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
    â”‚  which ad next? â”‚
    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
             â”‚
             â–¼
    somewhere here, our
    ranking system runs
             â”‚
             â–¼
    (harder than it sounds)
```

</td>
<td width="45%">

Ad ranking for post-transaction placements.

The interesting part isn't predicting clicksâ€”it's everything around it: exploration vs exploitation, feedback loops, knowing when to retrain.

</td>
</tr>
</table>

<br/>

## Â· problems i find interesting Â·

<table>
<tr>
<td width="50%">

### ğŸ° exploration vs exploitation

new campaigns have no data. show them and risk revenue, or don't and never learn.

our team uses thompson samplingâ€”balancing this is more art than science.

</td>
<td width="50%">

### ğŸ”„ feedback loops

today's training data was shaped by yesterday's model. the ads users saw were already filtered.

untangling this is humbling.

</td>
</tr>
<tr>
<td width="50%">

### ğŸ§¹ boring > clever

spent weeks on fancy architectures. adding `local_hour_of_day` helped more.

simple features usually win.

</td>
<td width="50%">

### â±ï¸ when to retrain

too often = chasing noise  
too rarely = drift

still iterating on this.

</td>
</tr>
</table>

<br/>

## Â· currently learning Â·

<div align="center">

```
                    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
                    â”‚         where my head is at              â”‚
                    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
                                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                            â”‚                            â”‚
          â–¼                            â–¼                            â–¼
   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®            â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®            â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
   â”‚  LLMs &     â”‚            â”‚   Causal    â”‚            â”‚  Online     â”‚
   â”‚  Gen AI     â”‚            â”‚  Inference  â”‚            â”‚  Learning   â”‚
   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯            â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯            â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
          â”‚                            â”‚                            â”‚
          â–¼                            â–¼                            â–¼
    Â· prompt eng          Â· uplift modeling         Â· contextual bandits
    Â· RAG pipelines       Â· counterfactuals         Â· continuous adaptation
    Â· agents              Â· beyond A/B tests        Â· reward shaping
    Â· function calling
```

</div>

<br/>

<details>
<summary><b>ğŸ“š reading & experimenting</b></summary>

<br/>

<table>
<tr>
<td width="50%">

**on the nightstand**

```
â—¦ designing ml systems
  chip huyen

â—¦ causal inference in statistics  
  judea pearl

â—¦ bandit algorithms
  lattimore & szepesvÃ¡ri

â—¦ papers on llm evaluation
  & alignment
```

</td>
<td width="50%">

**hands-on lately**

```
â—¦ langchain / llamaindex
  for doc retrieval

â—¦ claude api
  for workflow tools

â—¦ llm-assisted debugging
  (asking ai why my model broke)

â—¦ small rag experiments
  on internal docs
```

</td>
</tr>
</table>

</details>

<br/>

## Â· lessons learned Â·

<details>
<summary><b>on features</b></summary>

<br/>

```
    âœ“ worked                              âœ— didn't
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    position (1 vs 4 is huge)             day of week (too noisy)
    local hour (not utc!)                 exact age (buckets better)
    campaign recency signals              most third-party enrichment
    state-level geo                       zip code (too sparse)
```

</details>

<details>
<summary><b>on systems</b></summary>

<br/>

```
    â—¦ simple models + good features  >  complex models + mediocre features
    â—¦ logging is the actual hard part
    â—¦ "works on my machine" is a lifestyle
    â—¦ most ml problems are data problems wearing a trench coat
```

</details>

<details>
<summary><b>on learning</b></summary>

<br/>

```
    â—¦ reading papers is good, implementing is better
    â—¦ the tutorial â†’ production gap is where learning happens  
    â—¦ explaining simply = understanding deeply
    â—¦ staying curious > staying current
```

</details>

<br/>

## Â· tools Â·

<div align="center">

<br/>

`python` Â· `pyspark` Â· `sql` Â· `xgboost` Â· `databricks` Â· `mlflow`

<br/>

<sub>exploring: `langchain` Â· `huggingface` Â· `anthropic/openai apis`</sub>

<br/>

</div>

<br/>

## Â· background Â·

```
now         â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
  â”‚         â”‚  fluent Â· data scientist                   â”‚
  â”‚         â”‚  ad ranking Â· exploration Â· ml systems     â”‚
  â”‚         â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  â”‚
  â”‚         â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
2022        â”‚  bed bath & beyond Â· data scientist        â”‚
  â”‚         â”‚  targeting Â· store analytics Â· recs        â”‚
  â”‚         â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
  â”‚
2018        â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
            â”‚  stevens institute Â· ms information systemsâ”‚
            â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

<br/>

## Â· outside work Â·

<div align="center">

<table>
<tr>
<td align="center">
<br/>
â˜•<br/>
<sub>coffee</sub><br/>
<sub><sup>still chasing the</sup></sub><br/>
<sub><sup>perfect cortado</sup></sub>
<br/><br/>
</td>
<td align="center">
<br/>
ğŸ¬<br/>
<sub>films</sub><br/>
<sub><sup>narrative structure</sup></sub><br/>
<sub><sup>is just architecture</sup></sub>
<br/><br/>
</td>
<td align="center">
<br/>
ğŸ“š<br/>
<sub>reading</sub><br/>
<sub><sup>ml papers, sci-fi,</sup></sub><br/>
<sub><sup>occasional philosophy</sup></sub>
<br/><br/>
</td>
<td align="center">
<br/>
ğŸ¤<br/>
<sub>singing</sub><br/>
<sub><sup>badly, but</sup></sub><br/>
<sub><sup>enthusiastically</sup></sub>
<br/><br/>
</td>
<td align="center">
<br/>
ğŸ—£ï¸<br/>
<sub>languages</sub><br/>
<sub><sup>english Â· hindi</sup></sub><br/>
<sub><sup>marathi</sup></sub>
<br/><br/>
</td>
</tr>
</table>

</div>

<br/>

---

<div align="center">

<sub>happy to chat about ranking systems, bandits, llms, or coffee</sub>

</div>
